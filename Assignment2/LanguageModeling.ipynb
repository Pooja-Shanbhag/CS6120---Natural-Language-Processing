{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageModeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NULabTMN/ps2-PoojaKShanbhag/blob/master/LanguageModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "moWB9udaKesP"
      },
      "source": [
        "Your task is to train *character-level* language models. \n",
        "You will train unigram, bigram, and trigram character level models on a collection of books from Project Gutenberg. You will then use these trained English language models to distinguish English documents from Brazilian Portuguese documents in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gHFJmuftHJld",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import httpimport\n",
        "\n",
        "with httpimport.remote_repo(['lm_helper'], 'https://raw.githubusercontent.com/jasoriya/CS6120-PS2-support/master/utils/'):\n",
        "  from lm_helper import get_train_data, get_test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8U0UCuyHQkai"
      },
      "source": [
        "This code loads the training and test data. Each dataset is a list of books. Each book contains a list of sentences, and each sentence contains a list of words. For building a character language model, you should join the words of a sentence together with a space character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6x0pfuiEChTh",
        "colab": {}
      },
      "source": [
        "# get the train and test data\n",
        "train = get_train_data()\n",
        "test, test_files = get_test_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw9ikN7D8Euu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def uni_statistics(listOfSentences):\n",
        "    count_vec_unigram = CountVectorizer(analyzer = 'char', ngram_range = (1,1), lowercase=False)\n",
        "    uni_count_list = count_vec_unigram.fit_transform(listOfSentences).toarray().sum(axis=0)\n",
        "    uni_word_list = count_vec_unigram.get_feature_names()\n",
        "\n",
        "    uni_stat = dict(zip(uni_word_list,uni_count_list))\n",
        "   # print(len(uni_stat))\n",
        "    return uni_stat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR2-dBw38Eu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bi_statistics(listOfSentences):\n",
        "    \n",
        "    count_vec_bigram = CountVectorizer(analyzer = 'char', ngram_range = (2,2), lowercase=False)\n",
        "    bi_count_list = count_vec_bigram.fit_transform(listOfSentences).toarray().sum(axis=0)\n",
        "    bi_word_list = count_vec_bigram.get_feature_names()\n",
        "\n",
        "    bi_stat = dict(zip(bi_word_list,bi_count_list))\n",
        "  #  print(len(bi_stat))\n",
        "    \n",
        "    return bi_stat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5phpBXxV8Eu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tri_statistics(listOfSentences):\n",
        "    \n",
        "    count_vec_trigram = CountVectorizer(analyzer = 'char', ngram_range = (3,3), lowercase=False)\n",
        "    tri_count_list = count_vec_trigram.fit_transform(listOfSentences).toarray().sum(axis=0)\n",
        "    tri_word_list = count_vec_trigram.get_feature_names()\n",
        "\n",
        "    tri_stat = dict(zip(tri_word_list,tri_count_list))\n",
        "\n",
        "    #print(len(tri_stat))\n",
        "    return tri_stat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_WAO9VjFLArq"
      },
      "source": [
        "## 1.1\n",
        "Collect statistics on the unigram, bigram, and trigram character counts.\n",
        "\n",
        "If your machine takes a long time to perform this computation, you may save these counts to files in your github repository and load them on request. This is not necessary, however.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyc8MWYV8EvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code here\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "listOfSentences = []\n",
        "for books in train:\n",
        "    for sentence in books:\n",
        "        listOfSentences.append(' '.join(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnMtQ6pf8EvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uni_stat = uni_statistics(listOfSentences)\n",
        "total_uni_full = sum(uni_stat.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLaLc1S18EvM",
        "colab_type": "code",
        "colab": {},
        "outputId": "6686a635-7ed7-4331-c218-7d28784a8956"
      },
      "source": [
        "print(total_uni_full)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12010505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXoS81JH8EvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bi_stat = bi_statistics(listOfSentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vV6YOqQ8EvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tri_stat = tri_statistics(listOfSentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6MBciI88EvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "#print(len(listOfSentences))\n",
        "length = math.ceil(len(listOfSentences)*0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu_jsvms8EvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get stats on 80% of training data\n",
        "u_stat_80 = uni_statistics(listOfSentences[:length])\n",
        "total_uni_80 = sum(u_stat_80.values())\n",
        "#print(total_uni_80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPRbUpkM8Evb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_stat_80 = bi_statistics(listOfSentences[:length])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USEtHIBd8Evd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_stat_80 = tri_statistics(listOfSentences[:length])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RS3mnaIvQnhI"
      },
      "source": [
        "## 1.2\n",
        "Calculate the perplexity for each document in the test set using linear interpolation smoothing method. For determining λs for linear interpolation, you can divide the training data into a new training set (80%) and a held-out set (20%), then using grid search method:\n",
        "Choose ~10 values of λ to test using grid search on held-out data.\n",
        "\n",
        "Some documents in the test set are in Brazilian Portuguese. Identify them as follows: \n",
        "  - Sort by perplexity and set a cut-off threshold. All the documents above this threshold score should be categorized as Brazilian Portuguese. \n",
        "  - Print the file names (from `test_files`) and perplexities of the documents above the threshold\n",
        "\n",
        "    ```\n",
        "        file name, score\n",
        "        file name, score\n",
        "        . . .\n",
        "        file name, score\n",
        "    ```\n",
        "\n",
        "  - Copy this list of filenames and manually annotate them as being correctly or incorrectly labeled as Portuguese.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l7lia_m8Evh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcu_Y7F48Evj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unigram_probability(word,flag):\n",
        "    if flag:\n",
        "        return uni_stat.get(word,UNK)/total_uni_full\n",
        "    else:\n",
        "        return u_stat_80.get(word,UNK)/total_uni_80"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2x3dpnB8Evm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U219s2sG8Evp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bigram_probabililty(w1,w2,flag):\n",
        "    if flag:\n",
        "        return bi_stat.get(w1+w2,0)/uni_stat.get(w1,UNK)\n",
        "    else:\n",
        "        return b_stat_80.get(w1+w2,0)/u_stat_80.get(w1,UNK)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON1nqaq08Evr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trigram_probability(w1,w2,w3,flag):\n",
        "    if flag:\n",
        "        return tri_stat.get(w1+w2+w3,0)/bi_stat.get(w1+w2,UNK)\n",
        "    else:\n",
        "        return t_stat_80.get(w1+w2+w3,0)/b_stat_80.get(w1+w2,UNK)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF_AMqSp8Evt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getLinearInterpolation(w1,w2,w3, l, flag):\n",
        "    return (l[0]*trigram_probability(w1,w2,w3,flag)+l[1]*bigram_probabililty(w2,w3,flag)+l[2]*unigram_probability(w3,flag))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etaknS7W8Evv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculateInterpolationEntropy(m,sentence,l,flag):\n",
        "    entropy = 0\n",
        "    for i in range(0,len(sentence)-2):\n",
        "        w1, w2, w3 = sentence[i:i+3]\n",
        "       # print(w1,w2,w3)\n",
        "        p = getLinearInterpolation(w1,w2,w3,l,flag)\n",
        "       # print(p)\n",
        "        entropy = entropy + np.log2(p)\n",
        "   # print(entropy*-1)\n",
        "    entropy = (1/m)*(-entropy)\n",
        "    return entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chKAOgD_8Evx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perplexityCalc(entropy):\n",
        "    #print(2**(-entropy))\n",
        "    return 2**(entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QQF4HhQGOZD8",
        "scrolled": true,
        "colab": {},
        "outputId": "83725968-60df-4d14-9545-52e31b722d69"
      },
      "source": [
        "# Your code here\n",
        "import numpy as np\n",
        "held_out = listOfSentences[length:]\n",
        "held_out_doc = ' '.join(held_out)\n",
        "\n",
        "#print(held_out_doc[:5])\n",
        "#print(len(held_out))\n",
        "\n",
        "lambdas = [[0.33,0.33,0.33], [0.4,0.3,0.3], [0.8,0.1,0.1], [0.1,0.8,0.1], [0.2,0.2,0.6], [0.2,0.6,0.2], [0.55,0.25,0.2],\n",
        "           [0.95,0.025,0.025],[0.3, 0.1, 0.6],[0.3, 0.6, 0.1],[0.1, 0.3, 0.6],[0.5, 0.1, 0.4],[0.49,0.49,0.02],[0.02,0.49,0.49],\n",
        "           [0.49,0.02,0.49]]\n",
        "\n",
        "perplexity = []\n",
        "M = len(held_out)\n",
        "for l in lambdas:\n",
        "    e = calculateInterpolationEntropy(M,held_out_doc, l,False)\n",
        "    perp = perplexityCalc(e)\n",
        "    perplexity.append(perp)\n",
        "    \n",
        "index = perplexity.index(min(perplexity))\n",
        "finalL = lambdas[index]\n",
        "#print(perplexity[:20])\n",
        "print(finalL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.95, 0.025, 0.025]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnHKPULB8Ev1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docSentences = []\n",
        "for doc in test:\n",
        "    listOfTestSent = []\n",
        "    for sentence in doc:\n",
        "        listOfTestSent.append(' '.join(sentence))\n",
        "    docSentences.append(' '.join(listOfTestSent))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L16q7Wcb8Ev3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = {\"document\":docSentences, \"file name\":test_files, \"language\" : \"\", \"perplexity\" : np.nan, \"isCorrectLang\":False}\n",
        "dataFrame = pd.DataFrame(dictionary)\n",
        "\n",
        "for i in range(len(dataFrame)):\n",
        "    if dataFrame[\"file name\"].iloc[i].endswith('.txt'):\n",
        "        dataFrame[\"language\"].iloc[i]= 'pr'\n",
        "    else:\n",
        "        dataFrame[\"language\"].iloc[i]= 'en'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAI-noq78Ev5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(len(dataFrame)):\n",
        "    eachLen = len(dataFrame[\"document\"].iloc[i])\n",
        "    e = calculateInterpolationEntropy(eachLen,dataFrame[\"document\"].iloc[i], finalL, True)\n",
        "    dataFrame[\"perplexity\"].iloc[i] = perplexityCalc(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjkdzObJ8Ev7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZh88HaB8Ev9",
        "colab_type": "code",
        "colab": {},
        "outputId": "722ddf1c-6009-4b25-c4d7-272e321ee902"
      },
      "source": [
        "\n",
        "for i in range(len(dataFrame)):\n",
        "    if dataFrame['perplexity'].iloc[i] >= threshold and dataFrame['language'].iloc[i] == 'pr' :\n",
        "        dataFrame['isCorrectLang'].iloc[i] = True\n",
        "    elif dataFrame['perplexity'].iloc[i] < threshold and dataFrame['language'].iloc[i] == 'en' :\n",
        "        dataFrame['isCorrectLang'].iloc[i] = True\n",
        "dataFrame = dataFrame.sort_values(by=['perplexity'])\n",
        "print(dataFrame[170:220])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              document     file name language  \\\n",
            "123  Enrique Jorda , conductor and musical director...          ca32       en   \n",
            "199  St. Johns , Mich. , April 19 . -- A jury of se...          ca21       en   \n",
            "47   Resentment welled up yesterday among Democrati...          ca07       en   \n",
            "206  ( Do start fires one or two hours ahead of tim...          ce14       en   \n",
            "29   The most surprising thing about the Twenty-sec...          cb25       en   \n",
            "114  The presidency : talking and listening Though ...          ca42       en   \n",
            "136  Austin , Texas -- Committee approval of Gov. P...          ca02       en   \n",
            "188  Knowing specifically what the many feed additi...          ce27       en   \n",
            "126  City Controller Alexander Hemphill charged Tue...          ca09       en   \n",
            "196  About 70 North Providence taxpayers made appea...          ca24       en   \n",
            "41   If the Cardinals heed Manager Gene Mauch of th...          ca15       en   \n",
            "124  California Democrats this weekend will take th...          cb11       en   \n",
            "61   Rookie Ron Nischwitz continued his pinpoint pi...          ca13       en   \n",
            "142  Greer Garson , world-famous star of stage , sc...          ca29       en   \n",
            "72   The design of a mechanical interlocking frame ...          ce07       en   \n",
            "52   When Mickey Charles Mantle , the New York Yank...          ca39       en   \n",
            "134  Into Washington on President-elect John F. Ken...          ca40       en   \n",
            "215  To hold a herd of cattle on a new range till t...          cf35       en   \n",
            "109  Austin , Texas -- A Texas halfback who doesn't...          ca12       en   \n",
            "218  Asilomar , March 26 Vast spraying programs con...          ca25       en   \n",
            "131  After being closed for seven months , the Gard...          ca17       en   \n",
            "135  Hotel Escape's Bonanza room has a real bonanza...          ca31       en   \n",
            "150  As autumn starts its annual sweep , few Americ...          cc15       en   \n",
            "104  Salem ( special ) -- For a second month in a r...          ca23       en   \n",
            "214  The average reader of this magazine owns more ...          ce10       en   \n",
            "216  Santa Barbara -- `` The present recovery movem...          ca27       en   \n",
            "3    Miami , Fla. , March 17 -- The Orioles tonight...          ca11       en   \n",
            "118  Romantic news concerns Mrs. Joan Monroe Armour...          ca16       en   \n",
            "19   `` A Night in New Orleans '' is the gayety pla...          ca18       en   \n",
            "130  Orlando , Fla. , Feb. 2 -- The best 2-year-old...          ce09       en   \n",
            "180  Centro Nacional de Pesquisa de Soja ( CNPSo ) ...   ag94fe1.txt       pr   \n",
            "144  Pelo menos cinco candidatos de o PMDB a govern...  br94ab02.txt       pr   \n",
            "17   Os sojicultores brasileiros invadiram o Paragu...  ag94ja11.txt       pr   \n",
            "202  O fim melancólico de a revisão constitucional ...  br94ju01.txt       pr   \n",
            "101  Covas apressou se em anunciar anteontem três s...  br94de01.txt       pr   \n",
            "84   A primeira avaliação científica de os reflexos...  br94jl01.txt       pr   \n",
            "69   Costa Sena foi um de os grandes nomes de a pol...  br94ja04.txt       pr   \n",
            "89   brasil Críticas de sobra ; Mantendo distância ...  br94ma01.txt       pr   \n",
            "113  Com US$ 300 mensais é possível manter um caval...   ag94mr1.txt       pr   \n",
            "75   Criadores brasileiros fazem remate em a Bolívi...  ag94ou04.txt       pr   \n",
            "141  Agricultores gaúchos , paranaenses , mineiros ...  ag94de06.txt       pr   \n",
            "122  Exposição Nacional do Cavalo Árabe começa sext...  ag94no01.txt       pr   \n",
            "15   Exposição e pregão de andaluz exibem cerca de ...  ag94jl12.txt       pr   \n",
            "162  Um de os momentos mais tensos de a CPI de o Co...   br94fe1.txt       pr   \n",
            "172  Peões boiadeiros montam atrás de prêmios em a ...  ag94ag02.txt       pr   \n",
            "210  Jersei atinge média de Cr$ 1,4 milhão em a ven...  ag94ab12.txt       pr   \n",
            "21   Chamava a atenção , ontem , o abatimento de o ...  br94ag01.txt       pr   \n",
            "137  gril Associação quer transformar produto em co...  ag94ma03.txt       pr   \n",
            "51   Coluna \" Moeda Verde \" traz as relações de tro...  ag94ju07.txt       pr   \n",
            "1    Três remates de QM faturam R$ 720 mil com vend...  ag94se06.txt       pr   \n",
            "\n",
            "     perplexity  isCorrectLang  \n",
            "123   10.890525           True  \n",
            "199   10.900405           True  \n",
            "47    10.916983           True  \n",
            "206   11.037627           True  \n",
            "29    11.068619           True  \n",
            "114   11.162815           True  \n",
            "136   11.180820           True  \n",
            "188   11.197149           True  \n",
            "126   11.212291           True  \n",
            "196   11.216358           True  \n",
            "41    11.249632           True  \n",
            "124   11.308032           True  \n",
            "61    11.377749           True  \n",
            "142   11.418208           True  \n",
            "72    11.565090           True  \n",
            "52    11.609084           True  \n",
            "134   11.632428           True  \n",
            "215   11.830031           True  \n",
            "109   11.832608           True  \n",
            "218   11.890923           True  \n",
            "131   11.927899           True  \n",
            "135   11.954918           True  \n",
            "150   11.991383           True  \n",
            "104   12.062785           True  \n",
            "214   12.115252           True  \n",
            "216   12.183920           True  \n",
            "3     12.234286           True  \n",
            "118   12.313054           True  \n",
            "19    12.369700           True  \n",
            "130   16.744371           True  \n",
            "180   34.115323           True  \n",
            "144   34.612755           True  \n",
            "17    34.864838           True  \n",
            "202   35.191417           True  \n",
            "101   35.371679           True  \n",
            "84    35.501879           True  \n",
            "69    36.294602           True  \n",
            "89    36.459687           True  \n",
            "113   36.628729           True  \n",
            "75    36.652352           True  \n",
            "141   36.756155           True  \n",
            "122   36.819581           True  \n",
            "15    36.949616           True  \n",
            "162   37.163726           True  \n",
            "172   37.172972           True  \n",
            "210   37.584834           True  \n",
            "21    37.637404           True  \n",
            "137   38.212355           True  \n",
            "51    38.405124           True  \n",
            "1     39.885071           True  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ8otHN08Ev_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aQl2u_giVW5e"
      },
      "source": [
        "## 1.3\n",
        "Build a trigram language model with add-λ smoothing (use λ = 0.1).\n",
        "\n",
        "Sort the test documents by perplexity and perform a check for Brazilian Portuguese documents as above:\n",
        "\n",
        "  - Observe the perplexity scores and set a cut-off threshold. All the documents above this threshold score should be categorized as Brazilian Portuguese. \n",
        "  - Print the file names and perplexities of the documents above the threshold\n",
        "\n",
        "  ```\n",
        "      file name, score\n",
        "      file name, score\n",
        "      . . .\n",
        "      file name, score\n",
        "  ```\n",
        "\n",
        "  - Copy this list of filenames and manually annotate them for correctness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsoUN8kY8EwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = 0.1\n",
        "\n",
        "trigram_vocab = sum(tri_stat.values())\n",
        "def addKlambaProb(w1,w2,w3):\n",
        "    return (tri_stat.get(w1+w2+w3,0)+l)/(bi_stat.get(w1+w2,0)+(l*len(tri_stat))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ZiNhJs8EwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(tri_stat.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpyfBdzr8EwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculateAddKEntropy(sentence,m):\n",
        "    entropy = 0\n",
        "    for i in range(0,len(sentence)-2):\n",
        "        w1, w2, w3 = sentence[i:i+3]\n",
        "       # print(w1,w2,w3)\n",
        "        p = addKlambaProb(w1,w2,w3)\n",
        "        #print(p)\n",
        "        entropy = entropy + np.log2(p)\n",
        "    #print(entropy*-1)\n",
        "    entropy = (1/m)*(-entropy)\n",
        "    return entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IGUTEk8QUehL",
        "colab": {}
      },
      "source": [
        "# Your code here\n",
        "test_prep = []\n",
        "i = 0\n",
        "for i in range(len(docSentences)):\n",
        "#     e = calculateInterpolationEntropy(doc,finalL, True)\n",
        "#     test_perp.append(perplexityCalc(e))\n",
        "    eachLen = len(dataFrame[\"document\"].iloc[i])\n",
        "    e = calculateAddKEntropy(dataFrame[\"document\"].iloc[i], eachLen)\n",
        "    dataFrame[\"perplexity\"].iloc[i] = perplexityCalc(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr-RyMfN8EwK",
        "colab_type": "code",
        "colab": {},
        "outputId": "35a5b7be-3d35-464e-e46e-170f704e614a"
      },
      "source": [
        "threshold = 40\n",
        "for i in range(len(dataFrame)):\n",
        "    if dataFrame['perplexity'].iloc[i] >= threshold and dataFrame['language'].iloc[i] == 'pr' :\n",
        "        dataFrame['isCorrectLang'].iloc[i] = True\n",
        "    elif dataFrame['perplexity'].iloc[i] < threshold and dataFrame['language'].iloc[i] == 'en' :\n",
        "        dataFrame['isCorrectLang'].iloc[i] = True\n",
        "dataFrame2 = dataFrame.copy()\n",
        "dataFrame2 = dataFrame2.sort_values(by=['perplexity'])\n",
        "print(dataFrame2[170:220])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              document     file name language  \\\n",
            "154  Philadelphia , Jan. 23 -- Nick Skorich , the l...          ca14       en   \n",
            "33   Mischa Elman shared last night's Lewisohn Stad...          cc11       en   \n",
            "56   Too often a beginning bodybuilder has to do hi...          ce01       en   \n",
            "199  St. Johns , Mich. , April 19 . -- A jury of se...          ca21       en   \n",
            "188  Knowing specifically what the many feed additi...          ce27       en   \n",
            "136  Austin , Texas -- Committee approval of Gov. P...          ca02       en   \n",
            "29   The most surprising thing about the Twenty-sec...          cb25       en   \n",
            "196  About 70 North Providence taxpayers made appea...          ca24       en   \n",
            "114  The presidency : talking and listening Though ...          ca42       en   \n",
            "126  City Controller Alexander Hemphill charged Tue...          ca09       en   \n",
            "124  California Democrats this weekend will take th...          cb11       en   \n",
            "142  Greer Garson , world-famous star of stage , sc...          ca29       en   \n",
            "41   If the Cardinals heed Manager Gene Mauch of th...          ca15       en   \n",
            "61   Rookie Ron Nischwitz continued his pinpoint pi...          ca13       en   \n",
            "134  Into Washington on President-elect John F. Ken...          ca40       en   \n",
            "72   The design of a mechanical interlocking frame ...          ce07       en   \n",
            "52   When Mickey Charles Mantle , the New York Yank...          ca39       en   \n",
            "218  Asilomar , March 26 Vast spraying programs con...          ca25       en   \n",
            "135  Hotel Escape's Bonanza room has a real bonanza...          ca31       en   \n",
            "150  As autumn starts its annual sweep , few Americ...          cc15       en   \n",
            "214  The average reader of this magazine owns more ...          ce10       en   \n",
            "216  Santa Barbara -- `` The present recovery movem...          ca27       en   \n",
            "104  Salem ( special ) -- For a second month in a r...          ca23       en   \n",
            "109  Austin , Texas -- A Texas halfback who doesn't...          ca12       en   \n",
            "131  After being closed for seven months , the Gard...          ca17       en   \n",
            "3    Miami , Fla. , March 17 -- The Orioles tonight...          ca11       en   \n",
            "215  To hold a herd of cattle on a new range till t...          cf35       en   \n",
            "118  Romantic news concerns Mrs. Joan Monroe Armour...          ca16       en   \n",
            "19   `` A Night in New Orleans '' is the gayety pla...          ca18       en   \n",
            "130  Orlando , Fla. , Feb. 2 -- The best 2-year-old...          ce09       en   \n",
            "180  Centro Nacional de Pesquisa de Soja ( CNPSo ) ...   ag94fe1.txt       pr   \n",
            "144  Pelo menos cinco candidatos de o PMDB a govern...  br94ab02.txt       pr   \n",
            "101  Covas apressou se em anunciar anteontem três s...  br94de01.txt       pr   \n",
            "17   Os sojicultores brasileiros invadiram o Paragu...  ag94ja11.txt       pr   \n",
            "202  O fim melancólico de a revisão constitucional ...  br94ju01.txt       pr   \n",
            "84   A primeira avaliação científica de os reflexos...  br94jl01.txt       pr   \n",
            "69   Costa Sena foi um de os grandes nomes de a pol...  br94ja04.txt       pr   \n",
            "162  Um de os momentos mais tensos de a CPI de o Co...   br94fe1.txt       pr   \n",
            "75   Criadores brasileiros fazem remate em a Bolívi...  ag94ou04.txt       pr   \n",
            "89   brasil Críticas de sobra ; Mantendo distância ...  br94ma01.txt       pr   \n",
            "122  Exposição Nacional do Cavalo Árabe começa sext...  ag94no01.txt       pr   \n",
            "15   Exposição e pregão de andaluz exibem cerca de ...  ag94jl12.txt       pr   \n",
            "113  Com US$ 300 mensais é possível manter um caval...   ag94mr1.txt       pr   \n",
            "141  Agricultores gaúchos , paranaenses , mineiros ...  ag94de06.txt       pr   \n",
            "210  Jersei atinge média de Cr$ 1,4 milhão em a ven...  ag94ab12.txt       pr   \n",
            "172  Peões boiadeiros montam atrás de prêmios em a ...  ag94ag02.txt       pr   \n",
            "21   Chamava a atenção , ontem , o abatimento de o ...  br94ag01.txt       pr   \n",
            "137  gril Associação quer transformar produto em co...  ag94ma03.txt       pr   \n",
            "51   Coluna \" Moeda Verde \" traz as relações de tro...  ag94ju07.txt       pr   \n",
            "1    Três remates de QM faturam R$ 720 mil com vend...  ag94se06.txt       pr   \n",
            "\n",
            "     perplexity  isCorrectLang  \n",
            "154   13.477552           True  \n",
            "33    13.478097           True  \n",
            "56    13.556825           True  \n",
            "199   13.572581           True  \n",
            "188   13.651373           True  \n",
            "136   13.839235           True  \n",
            "29    13.871761           True  \n",
            "196   13.942452           True  \n",
            "114   13.957774           True  \n",
            "126   13.991128           True  \n",
            "124   14.049285           True  \n",
            "142   14.380558           True  \n",
            "41    14.408557           True  \n",
            "61    14.519966           True  \n",
            "134   14.550601           True  \n",
            "72    14.689981           True  \n",
            "52    14.859526           True  \n",
            "218   15.127248           True  \n",
            "135   15.203427           True  \n",
            "150   15.270067           True  \n",
            "214   15.446362           True  \n",
            "216   15.480408           True  \n",
            "104   15.530213           True  \n",
            "109   15.700292           True  \n",
            "131   15.908816           True  \n",
            "3     15.966256           True  \n",
            "215   16.278324           True  \n",
            "118   16.395054           True  \n",
            "19    17.451258           True  \n",
            "130   23.890384           True  \n",
            "180   48.647437           True  \n",
            "144   48.703733           True  \n",
            "101   49.405102           True  \n",
            "17    49.715634           True  \n",
            "202   49.838642           True  \n",
            "84    50.208757           True  \n",
            "69    51.199275           True  \n",
            "162   52.198256           True  \n",
            "75    52.495390           True  \n",
            "89    52.602515           True  \n",
            "122   52.751342           True  \n",
            "15    53.149571           True  \n",
            "113   53.298789           True  \n",
            "141   53.439174           True  \n",
            "210   53.699307           True  \n",
            "172   53.718902           True  \n",
            "21    53.764259           True  \n",
            "137   55.447291           True  \n",
            "51    55.655224           True  \n",
            "1     58.221120           True  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bqhXTB5TXR25"
      },
      "source": [
        "## 1.4\n",
        "Based on your observation from above questions, compare linear interpolation and add-λ smoothing by listing out their pros and cons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFq1ECgDI6QG"
      },
      "source": [
        "1. In Linear Interpolation method, the articles are distinguished as english or portuguese by a margin of ~17 whereas in add-λ smoothing method the margin of ~25 . We can see that trigram model with add-λ smoothing distiguishes better than the combination of Unigram, bigram and trigram model in linear interpolation.\n",
        "2. In Linear-interpolation the existance of unigram , bigram models induces more bias than the trigram model. Whereas in Trigram model with add-λ smoothing there is only trigram model present so low bias. The add-λ smoothing method helps the trigram model to fix issue with unseen trigrams which is the disadvantage of trigram model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNoNbTvW8EwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}